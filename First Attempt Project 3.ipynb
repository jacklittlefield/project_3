{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Using Reddit's API for Predicting Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "In this project, we will practice two major skills. Collecting data via an API request and then building a binary predictor.\n",
    "\n",
    "As we discussed in week 2, and earlier today, there are two components to starting a data science problem: the problem statement, and acquiring the data.\n",
    "\n",
    "For this article, your problem statement will be: _What characteristics of a post on Reddit contribute most to what subreddit it belongs to?_\n",
    "\n",
    "Your method for acquiring the data will be scraping threads from at least two subreddits. \n",
    "\n",
    "Once you've got the data, you will build a classification model that, using Natural Language Processing and any other relevant features, predicts which subreddit a given post belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping Thread Info from Reddit.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. \n",
    "\n",
    "*NOTE*: Reddit will throw a [429 error](https://httpstatuses.com/429) when using the following code:\n",
    "```python\n",
    "res = requests.get(URL)\n",
    "```\n",
    "\n",
    "This is because Reddit has throttled python's default user agent. You'll need to set a custom `User-agent` to get your request to work.\n",
    "```python\n",
    "res = requests.get(URL, headers={'User-agent': 'YOUR NAME Bot 0.1'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://www.reddit.com/r/boardgames.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "result = requests.get(URL, headers={'User-agent': 'YOUR NAME Bot 0.1'})\n",
    "results = result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results commented to reduce "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `res.json()` to convert the response into a dictionary format and set this to a variable. \n",
    "\n",
    "```python\n",
    "data = res.json()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/r/boardgames Daily Discussion and Game Recommendations (September 06, 2018)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data']['children'][0]['data']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [p['data'] for p in data['data']['children']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting more results\n",
    "\n",
    "By default, Reddit will give you the top 25 posts:\n",
    "\n",
    "```python\n",
    "print(len(data['data']['children']))\n",
    "```\n",
    "\n",
    "If you want more, you'll need to do two things:\n",
    "1. Get the name of the last post: `data['data']['after']`\n",
    "2. Use that name to hit the following url: `http://www.reddit.com/r/boardgames.json?after=THE_AFTER_FROM_STEP_1`\n",
    "3. Create a loop to repeat steps 1 and 2 until you have a sufficient number of posts. \n",
    "\n",
    "*NOTE*: Reddit will limit the number of requests per second you're allowed to make. When you create your loop, be sure to add the following after each iteration.\n",
    "\n",
    "```python\n",
    "time.sleep(3) # sleeps 3 seconds before continuing```\n",
    "\n",
    "This will throttle your loop and keep you within Reddit's guidelines. You'll need to import the `time` library for this to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_9dgnby'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://www.reddit.com/r/nfl.json'\n",
    "lp = data['data']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.reddit.com/r/nfl.jsont3_9dgnby'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL+lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_9dijn8'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLPF = 'http://www.reddit.com/r/nfl.json'\n",
    "pf = requests.get(URLPF, headers = {'User-agent':'jacksbot'})\n",
    "dfp = pf.json()\n",
    "\n",
    "dfp['data']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.reddit.com/r/nfl.json\n",
      "0\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9dijn8\n",
      "1\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9djir8\n",
      "2\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9di8l5\n",
      "3\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9de84e\n",
      "4\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9daygm\n",
      "5\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9dagp6\n",
      "6\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cylim\n",
      "7\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9d1zpg\n",
      "8\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9dj0vz\n",
      "9\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9d2ytr\n",
      "10\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cz2zh\n",
      "11\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cw88a\n",
      "12\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cxzkx\n",
      "13\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9codnu\n",
      "14\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cnd18\n",
      "15\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cnryg\n",
      "16\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cq56k\n",
      "17\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ce43d\n",
      "18\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9chkuu\n",
      "19\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cdx9u\n",
      "20\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c7z07\n",
      "21\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c953r\n",
      "22\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cbik1\n",
      "23\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cmt26\n",
      "24\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c8191\n",
      "25\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ccxmm\n",
      "26\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c6z73\n",
      "27\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c6uln\n",
      "28\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c65zz\n",
      "29\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c57zb\n",
      "30\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c693f\n",
      "31\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c4t3r\n",
      "32\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c4yz5\n",
      "33\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c3i5f\n",
      "34\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9bwti9\n",
      "35\n",
      "http://www.reddit.com/r/nfl.json\n",
      "36\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ddgfp\n",
      "37\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9djir8\n",
      "38\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9dazz4\n",
      "39\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9d8znb\n",
      "40\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9d6hbd\n",
      "41\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9d7x8r\n",
      "42\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9czrtj\n",
      "43\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cvypd\n",
      "44\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9dakdv\n",
      "45\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cw6nl\n",
      "46\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9coxte\n",
      "47\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cwdyq\n",
      "48\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cv3v2\n",
      "49\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cmk9c\n",
      "50\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cv2mm\n",
      "51\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cr10t\n",
      "52\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ctpyz\n",
      "53\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cl4j4\n",
      "54\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ccskb\n",
      "55\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9crrt8\n",
      "56\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cdgkp\n",
      "57\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ceb6o\n",
      "58\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c6jbz\n",
      "59\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cbl69\n",
      "60\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c88fi\n",
      "61\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cggi1\n",
      "62\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9clf19\n",
      "63\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c4br4\n",
      "64\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c3tqc\n",
      "65\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c6kdm\n",
      "66\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c5jbl\n",
      "67\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c5045\n",
      "68\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c3y5l\n",
      "69\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c4q4d\n",
      "70\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9byrls\n",
      "71\n",
      "http://www.reddit.com/r/nfl.json\n",
      "72\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ddgfp\n",
      "73\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9djir8\n",
      "74\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9dkg5n\n",
      "75\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9d8znb\n",
      "76\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9d6hbd\n",
      "77\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9d7x8r\n",
      "78\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9czrtj\n",
      "79\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cvypd\n",
      "80\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9dakdv\n",
      "81\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cw6nl\n",
      "82\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9coxte\n",
      "83\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cwdyq\n",
      "84\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cv3v2\n",
      "85\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cmk9c\n",
      "86\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cv2mm\n",
      "87\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cr10t\n",
      "88\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ctpyz\n",
      "89\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cl4j4\n",
      "90\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ccskb\n",
      "91\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9crrt8\n",
      "92\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cdgkp\n",
      "93\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9ceb6o\n",
      "94\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c6jbz\n",
      "95\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cbl69\n",
      "96\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9c88fi\n",
      "97\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9cggi1\n",
      "98\n",
      "http://www.reddit.com/r/nfl.json?after=t3_9clf19\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.reddit.com/r/nfl.json'\n",
    "posts = []\n",
    "after = None\n",
    "var = 0\n",
    "\n",
    "\n",
    "for _ in range(100):\n",
    "    if after == None:\n",
    "        curent_url = url\n",
    "    else:\n",
    "        curent_url = url + '?after=' + after\n",
    "    print(curent_url)\n",
    "    res = requests.get(curent_url, headers = {'User-agent':'Jacks bot'})\n",
    "    if res.status_code != 200:\n",
    "        print('States Error', res.status_code)\n",
    "        break\n",
    "    print(var)\n",
    "    var += 1\n",
    "    curent_dict = res.json()\n",
    "    curent_posts = [p['data'] for p in curent_dict['data']['children']]\n",
    "    posts.extend(curent_posts)\n",
    "    after = curent_dict['data']['after']\n",
    "    time.sleep(1.2)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_9dk0mw'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "URLPF = 'http://www.reddit.com/r/personalfinance.json'\n",
    "pf = requests.get(URLPF, headers = {'User-agent':'jacksbot'})\n",
    "dfp = pf.json()\n",
    "\n",
    "dfp['data']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2477"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV\n",
    "You may do this regularly while scraping data as well, so that if your scraper stops of your computer crashes, you don't lose all your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_data = pd.DataFrame(posts)\n",
    "pd.DataFrame(posts).to_csv('nfl_posts_thu.csv', index = False)\n",
    "\n",
    "# Export to csv\n",
    "pd.DataFrame(posts).to_csv('nfl_posts_thu.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thursday Talk Thread... Yes That's The Thread ...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Official rNFL Pick 'Em League</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ohrnberger: Le’Veon Bell’s teammates are brain...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After 214 days of waiting since SB 52, its fin...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Fanatics] Top selling jerseys in the preseaso...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is a \"franchise tag\" and why is it consid...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Le'Veon Bell's response to a post about OL com...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Quote of the day goes to Packers CB Kevin King...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Film Room Ep. 80: Sam Darnold is already t...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rams offered 'aggressive' package for Khalil M...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amari Cooper: We might have to 'score on every...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MJD: It’s funny to see all the Steelers player...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A few days before the opener, the Dolphins los...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ex NFL linemen George Foster on Steelers Locke...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mitch Trubisky says his mother woke him up Sat...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Why Did I Retire?</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>With a victory over the Houston Texans Week 1,...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>More Ramon Foster on Bell: “He’s making 7 time...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Field Yates: \"I can't recall players speaking ...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CBS to stream Super Bowl for free on mobile de...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jordan Reed expects to see “a healthy Jordan R...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>THE UNOFFICIAL WEEK ONE BOLD PREDICTIONS THREAD</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Steelers guard David DeCastro: \"We all thought...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Evaluating the NFL since the realignment</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RB James Conner on how much his offensive line...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Introducing the 2018 /r/NFL Conquest Map (Alte...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[Nick Underhill on Twitter] \"Someone asked me ...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DeCastro on Bell -- \"Just sit out the whole ye...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>More Pouncey: \"A star is born every year in th...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Marcus Peters is in Inglewood today giving awa...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>Broncos will keep Lynch on their 53-Roster for...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>As of the 4pm ET deadline, the Raiders were pl...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>A veteran surprise: Vikings are releasing DE B...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>The Effects of paying Elite Edge players marke...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>America's team has Canadian flavour for upcomi...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>[Daniels] Patriots have cut QB Danny Etling, p...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>Broncos cut half their 2017 draft class</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>The #Vikings are expected to release WR Kendal...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>Cowboys TE and former Baylor basketball star R...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>[Rules] Help solve Punt Fumble Debate please</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>Other teams with strong offers for Mack were G...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>Mike Freeman - “From one team executive who sp...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>#Cowboys have released Chaz Green</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>This is the first time ever that the Ravens pa...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>Cowboy cut RB Bo Scarbrough, according to a so...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>Players traded for two first-round picks since...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>Source: #Bears have agreed to trade DB Deiondr...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>Reporter to Ryan Pace one week ago: “So you’re...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>Giants will keep 4 QBs on the 53-man roster</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>Does Khalil Mack play week one for Chicago?</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>Raiders broadcaster Lincoln Kennedy insists Kh...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>Bears down to 53 man roster.</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>Howe: The Patriots have released former second...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>[Schefter] Unless another team steps up in a w...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>RB Chris Warren and K Eddy Piñeiro placed on i...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>Ravens have been fielding trade calls on QB Ro...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>Source: the Panthers have converted $6.8M of L...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>One team to watch in the Khalil Mack sweepstak...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>Buccaneers keep their entire draft class on th...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>Pelissero: One impact of the Khalil Mack deal:...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2477 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title subreddit\n",
       "0     Thursday Talk Thread... Yes That's The Thread ...       nfl\n",
       "1                         Official rNFL Pick 'Em League       nfl\n",
       "2     Ohrnberger: Le’Veon Bell’s teammates are brain...       nfl\n",
       "3     After 214 days of waiting since SB 52, its fin...       nfl\n",
       "4     [Fanatics] Top selling jerseys in the preseaso...       nfl\n",
       "5     What is a \"franchise tag\" and why is it consid...       nfl\n",
       "6     Le'Veon Bell's response to a post about OL com...       nfl\n",
       "7     Quote of the day goes to Packers CB Kevin King...       nfl\n",
       "8     The Film Room Ep. 80: Sam Darnold is already t...       nfl\n",
       "9     Rams offered 'aggressive' package for Khalil M...       nfl\n",
       "10    Amari Cooper: We might have to 'score on every...       nfl\n",
       "11    MJD: It’s funny to see all the Steelers player...       nfl\n",
       "12    A few days before the opener, the Dolphins los...       nfl\n",
       "13    Ex NFL linemen George Foster on Steelers Locke...       nfl\n",
       "14    Mitch Trubisky says his mother woke him up Sat...       nfl\n",
       "15                                    Why Did I Retire?       nfl\n",
       "16    With a victory over the Houston Texans Week 1,...       nfl\n",
       "17    More Ramon Foster on Bell: “He’s making 7 time...       nfl\n",
       "18    Field Yates: \"I can't recall players speaking ...       nfl\n",
       "19    CBS to stream Super Bowl for free on mobile de...       nfl\n",
       "20    Jordan Reed expects to see “a healthy Jordan R...       nfl\n",
       "21      THE UNOFFICIAL WEEK ONE BOLD PREDICTIONS THREAD       nfl\n",
       "22    Steelers guard David DeCastro: \"We all thought...       nfl\n",
       "23             Evaluating the NFL since the realignment       nfl\n",
       "24    RB James Conner on how much his offensive line...       nfl\n",
       "25    Introducing the 2018 /r/NFL Conquest Map (Alte...       nfl\n",
       "26    [Nick Underhill on Twitter] \"Someone asked me ...       nfl\n",
       "27    DeCastro on Bell -- \"Just sit out the whole ye...       nfl\n",
       "28    More Pouncey: \"A star is born every year in th...       nfl\n",
       "29    Marcus Peters is in Inglewood today giving awa...       nfl\n",
       "...                                                 ...       ...\n",
       "2447  Broncos will keep Lynch on their 53-Roster for...       nfl\n",
       "2448  As of the 4pm ET deadline, the Raiders were pl...       nfl\n",
       "2449  A veteran surprise: Vikings are releasing DE B...       nfl\n",
       "2450  The Effects of paying Elite Edge players marke...       nfl\n",
       "2451  America's team has Canadian flavour for upcomi...       nfl\n",
       "2452  [Daniels] Patriots have cut QB Danny Etling, p...       nfl\n",
       "2453            Broncos cut half their 2017 draft class       nfl\n",
       "2454  The #Vikings are expected to release WR Kendal...       nfl\n",
       "2455  Cowboys TE and former Baylor basketball star R...       nfl\n",
       "2456       [Rules] Help solve Punt Fumble Debate please       nfl\n",
       "2457  Other teams with strong offers for Mack were G...       nfl\n",
       "2458  Mike Freeman - “From one team executive who sp...       nfl\n",
       "2459                  #Cowboys have released Chaz Green       nfl\n",
       "2460  This is the first time ever that the Ravens pa...       nfl\n",
       "2461  Cowboy cut RB Bo Scarbrough, according to a so...       nfl\n",
       "2462  Players traded for two first-round picks since...       nfl\n",
       "2463  Source: #Bears have agreed to trade DB Deiondr...       nfl\n",
       "2464  Reporter to Ryan Pace one week ago: “So you’re...       nfl\n",
       "2465        Giants will keep 4 QBs on the 53-man roster       nfl\n",
       "2466        Does Khalil Mack play week one for Chicago?       nfl\n",
       "2467  Raiders broadcaster Lincoln Kennedy insists Kh...       nfl\n",
       "2468                       Bears down to 53 man roster.       nfl\n",
       "2469  Howe: The Patriots have released former second...       nfl\n",
       "2470  [Schefter] Unless another team steps up in a w...       nfl\n",
       "2471  RB Chris Warren and K Eddy Piñeiro placed on i...       nfl\n",
       "2472  Ravens have been fielding trade calls on QB Ro...       nfl\n",
       "2473  Source: the Panthers have converted $6.8M of L...       nfl\n",
       "2474  One team to watch in the Khalil Mack sweepstak...       nfl\n",
       "2475  Buccaneers keep their entire draft class on th...       nfl\n",
       "2476  Pelissero: One impact of the Khalil Mack deal:...       nfl\n",
       "\n",
       "[2477 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(posts).to_csv('nfl_posts_wed.csv', index = False)\n",
    "nfl_words = nfl_data[['title', 'subreddit']]\n",
    "nfl_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.reddit.com/r/soccer.json\n",
      "0\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dgely\n",
      "1\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dk3bl\n",
      "2\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d8hvw\n",
      "3\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dg0c7\n",
      "4\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d55s0\n",
      "5\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dizna\n",
      "6\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9daaik\n",
      "7\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dbz7m\n",
      "8\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d59pm\n",
      "9\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cvho7\n",
      "10\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cv0e3\n",
      "11\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ctsga\n",
      "12\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cvvho\n",
      "13\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cueyc\n",
      "14\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cznia\n",
      "15\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ckunr\n",
      "16\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ctmuy\n",
      "17\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cm6ai\n",
      "18\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cndu1\n",
      "19\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cotli\n",
      "20\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cmzt6\n",
      "21\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cc01o\n",
      "22\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cddcg\n",
      "23\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cjs1r\n",
      "24\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cekit\n",
      "25\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ccdrh\n",
      "26\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ce27h\n",
      "27\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ce2qz\n",
      "28\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cdgyh\n",
      "29\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cfxm3\n",
      "30\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9c2t1a\n",
      "31\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ceb4l\n",
      "32\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cd9rl\n",
      "33\n",
      "http://www.reddit.com/r/soccer.json\n",
      "34\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dgely\n",
      "35\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9djtxw\n",
      "36\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d9l2u\n",
      "37\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dawsb\n",
      "38\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d7crt\n",
      "39\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dizna\n",
      "40\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9daaik\n",
      "41\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dbz7m\n",
      "42\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d59pm\n",
      "43\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cvho7\n",
      "44\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cv0e3\n",
      "45\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ctsga\n",
      "46\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cvvho\n",
      "47\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cueyc\n",
      "48\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cznia\n",
      "49\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ckunr\n",
      "50\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ctmuy\n",
      "51\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cm6ai\n",
      "52\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cndu1\n",
      "53\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cotli\n",
      "54\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cmzt6\n",
      "55\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cc01o\n",
      "56\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cddcg\n",
      "57\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cjs1r\n",
      "58\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cekit\n",
      "59\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ccdrh\n",
      "60\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ce27h\n",
      "61\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ce2qz\n",
      "62\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cdgyh\n",
      "63\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cfxm3\n",
      "64\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9c2t1a\n",
      "65\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ceb4l\n",
      "66\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cd9rl\n",
      "67\n",
      "http://www.reddit.com/r/soccer.json\n",
      "68\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dgely\n",
      "69\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9djtxw\n",
      "70\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d9l2u\n",
      "71\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dawsb\n",
      "72\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d7crt\n",
      "73\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dizna\n",
      "74\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9daaik\n",
      "75\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9dbz7m\n",
      "76\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9d59pm\n",
      "77\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cvho7\n",
      "78\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cv0e3\n",
      "79\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ctsga\n",
      "80\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cvvho\n",
      "81\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cueyc\n",
      "82\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cznia\n",
      "83\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ckunr\n",
      "84\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ctmuy\n",
      "85\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cm6ai\n",
      "86\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cndu1\n",
      "87\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cotli\n",
      "88\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cmzt6\n",
      "89\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cc01o\n",
      "90\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cddcg\n",
      "91\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cjs1r\n",
      "92\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cekit\n",
      "93\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ccdrh\n",
      "94\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ce27h\n",
      "95\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9ce2qz\n",
      "96\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cdgyh\n",
      "97\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9cfxm3\n",
      "98\n",
      "http://www.reddit.com/r/soccer.json?after=t3_9c2t1a\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.reddit.com/r/soccer.json'\n",
    "posts = []\n",
    "after = None\n",
    "var = 0\n",
    "\n",
    "\n",
    "for _ in range(100):\n",
    "    if after == None:\n",
    "        curent_url = url\n",
    "    else:\n",
    "        curent_url = url + '?after=' + after\n",
    "    print(curent_url)\n",
    "    res = requests.get(curent_url, headers = {'User-agent':'Jacks bot'})\n",
    "    if res.status_code != 200:\n",
    "        print('States Error', res.status_code)\n",
    "        break\n",
    "    print(var)\n",
    "    var += 1\n",
    "    curent_dict = res.json()\n",
    "    curent_posts = [p['data'] for p in curent_dict['data']['children']]\n",
    "    posts.extend(curent_posts)\n",
    "    after = curent_dict['data']['after']\n",
    "    time.sleep(1.2)  \n",
    "    \n",
    "soccer_data = pd.DataFrame(posts)\n",
    "pd.DataFrame(posts).to_csv('soccer_posts.csv', index = False)\n",
    "\n",
    "# Export to csv\n",
    "#pd.DataFrame(posts).to_csv('soccer_posts.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(posts).to_csv('soccer_posts_thu.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "soccer_words = soccer_data[['title', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Throwback Thursday Thread [2018-09-06]</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daily Discussion [2018-09-06]</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A stray dog has become \"assistant coach\" of Pa...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sneijder: Eto'o played left winger for Mourinh...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If the plans for Girona-Barça are as Cope repo...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[OC] Three Bundesliga players have reached 100...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reporter: FC Barcelona was interested, why did...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[OC] Giggs, Rooney and Lampard are the 3 Premi...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Napoli have conceded 6 goals so far in 3 games...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Matteo Guendouzi is Arsenal's August Player of...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FC Bayern Crowd Visualization</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pione Sisto went to the airport for Slovakia m...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Isco to a journalist who asked how he prefers ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Giroud on his failure to score at World Cup - ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kazakhstan 0-1 Georgia - Giorgi Chakvetadze 69...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The official ball to be used during the UEFA N...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'Six months to go' Adam Johnson's sister says ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Manchester City nearly signed Luka Modric for ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Raul Jimenez on Chicharito - “He scores a lot ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jordan Henderson still re-watching Croatia def...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dani Ceballos: \"If Zidane had continued, I wou...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Understanding the conflict of the Danish NT in...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wolfsburg have terminated Kaylen Hinds' contra...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Free Agents by 2019</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Milinković-Savić's agent Mateja Kežman: \"He co...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Everson (goalkeeper) free-kick goal vs. Corint...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15 year old Luke Matheson made his debut for R...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Everson (goalkeeper) free-kick goal vs. Corint...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lorenzo Insigne scares Mario Balotelli during ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wilfried Zaha has contacted Crystal Palace to ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>Aged 18 years, 284 days, Dwight McNeil is the ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>FC Barcelona reacts to nominees for FIFA men b...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>Levante 1-[1] Valencia - Cheryshev 16'</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>Nimes 2-[3] PSG - Kylian Mbappe 77'</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>R. Ghezzal goal (Leicester [1]-2 Liverpool) 63'</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>Highlights Vitesse - Ajax</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>Mahmoud Trezeguet nice goal - Kasimpasa [2]-0 ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>Steven Gerrard: ‘People want a problem between...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>Feyenoord [2]-1 NAC Breda - Benjamin van Leer ...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>Nacional 0-{3] Benfica - Grimaldo</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>D. Yedlin goal (Man City 1-[1] Newcastle) 29'</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>Post-Match Thread: Vitesse 0-4 Ajax [Eredivisie]</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>MOTD2 Thread!</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>CFR Cluj 1-[1] Viitorul Constanța - Mihai Vodu...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>Manchester Utd fans pay for banner criticising...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>The top 3 for 'FIFA's The Best' to be announce...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>Karim Benzema has now scored against all 33 te...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>Match Thread: Lazio vs Frosinone [Italian Seri...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>Match Thread: Vitesse Arnhem vs Ajax Amsterdam...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>Alaves [2]-1 Espanyol - Ruben Sobrino 59'</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>The risk of a Harry Kane burnout presents a pr...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>Olympiakos [1]-0 PAS Giannina — Omar Elabdella...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>St. Pauli 2-[4] FC Köln - Sehrou Guirassy 57'</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>Former West Brom defender Gareth McAuley set t...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>RB Leipzig [1]-1 Düsseldorf - Jean-Kevin Augus...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>G. Bale goal (Real Madrid [1]-0 Leganés) 17'</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>Daniel Caligiuri (Schalke) penalty miss agains...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>Match Thread: Atalanta vs Cagliari [Italian Se...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>J.League 2018: Game Week 25 Highlights and Rep...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>League Roundup: Ekstraklasa [2018-09-02]</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title subreddit\n",
       "0                Throwback Thursday Thread [2018-09-06]    soccer\n",
       "1                         Daily Discussion [2018-09-06]    soccer\n",
       "2     A stray dog has become \"assistant coach\" of Pa...    soccer\n",
       "3     Sneijder: Eto'o played left winger for Mourinh...    soccer\n",
       "4     If the plans for Girona-Barça are as Cope repo...    soccer\n",
       "5     [OC] Three Bundesliga players have reached 100...    soccer\n",
       "6     Reporter: FC Barcelona was interested, why did...    soccer\n",
       "7     [OC] Giggs, Rooney and Lampard are the 3 Premi...    soccer\n",
       "8     Napoli have conceded 6 goals so far in 3 games...    soccer\n",
       "9     Matteo Guendouzi is Arsenal's August Player of...    soccer\n",
       "10                        FC Bayern Crowd Visualization    soccer\n",
       "11    Pione Sisto went to the airport for Slovakia m...    soccer\n",
       "12    Isco to a journalist who asked how he prefers ...    soccer\n",
       "13    Giroud on his failure to score at World Cup - ...    soccer\n",
       "14    Kazakhstan 0-1 Georgia - Giorgi Chakvetadze 69...    soccer\n",
       "15    The official ball to be used during the UEFA N...    soccer\n",
       "16    'Six months to go' Adam Johnson's sister says ...    soccer\n",
       "17    Manchester City nearly signed Luka Modric for ...    soccer\n",
       "18    Raul Jimenez on Chicharito - “He scores a lot ...    soccer\n",
       "19    Jordan Henderson still re-watching Croatia def...    soccer\n",
       "20    Dani Ceballos: \"If Zidane had continued, I wou...    soccer\n",
       "21    Understanding the conflict of the Danish NT in...    soccer\n",
       "22    Wolfsburg have terminated Kaylen Hinds' contra...    soccer\n",
       "23                                  Free Agents by 2019    soccer\n",
       "24    Milinković-Savić's agent Mateja Kežman: \"He co...    soccer\n",
       "25    Everson (goalkeeper) free-kick goal vs. Corint...    soccer\n",
       "26    15 year old Luke Matheson made his debut for R...    soccer\n",
       "27    Everson (goalkeeper) free-kick goal vs. Corint...    soccer\n",
       "28    Lorenzo Insigne scares Mario Balotelli during ...    soccer\n",
       "29    Wilfried Zaha has contacted Crystal Palace to ...    soccer\n",
       "...                                                 ...       ...\n",
       "2436  Aged 18 years, 284 days, Dwight McNeil is the ...    soccer\n",
       "2437  FC Barcelona reacts to nominees for FIFA men b...    soccer\n",
       "2438             Levante 1-[1] Valencia - Cheryshev 16'    soccer\n",
       "2439                Nimes 2-[3] PSG - Kylian Mbappe 77'    soccer\n",
       "2440    R. Ghezzal goal (Leicester [1]-2 Liverpool) 63'    soccer\n",
       "2441                          Highlights Vitesse - Ajax    soccer\n",
       "2442  Mahmoud Trezeguet nice goal - Kasimpasa [2]-0 ...    soccer\n",
       "2443  Steven Gerrard: ‘People want a problem between...    soccer\n",
       "2444  Feyenoord [2]-1 NAC Breda - Benjamin van Leer ...    soccer\n",
       "2445                  Nacional 0-{3] Benfica - Grimaldo    soccer\n",
       "2446      D. Yedlin goal (Man City 1-[1] Newcastle) 29'    soccer\n",
       "2447   Post-Match Thread: Vitesse 0-4 Ajax [Eredivisie]    soccer\n",
       "2448                                      MOTD2 Thread!    soccer\n",
       "2449  CFR Cluj 1-[1] Viitorul Constanța - Mihai Vodu...    soccer\n",
       "2450  Manchester Utd fans pay for banner criticising...    soccer\n",
       "2451  The top 3 for 'FIFA's The Best' to be announce...    soccer\n",
       "2452  Karim Benzema has now scored against all 33 te...    soccer\n",
       "2453  Match Thread: Lazio vs Frosinone [Italian Seri...    soccer\n",
       "2454  Match Thread: Vitesse Arnhem vs Ajax Amsterdam...    soccer\n",
       "2455          Alaves [2]-1 Espanyol - Ruben Sobrino 59'    soccer\n",
       "2456  The risk of a Harry Kane burnout presents a pr...    soccer\n",
       "2457  Olympiakos [1]-0 PAS Giannina — Omar Elabdella...    soccer\n",
       "2458      St. Pauli 2-[4] FC Köln - Sehrou Guirassy 57'    soccer\n",
       "2459  Former West Brom defender Gareth McAuley set t...    soccer\n",
       "2460  RB Leipzig [1]-1 Düsseldorf - Jean-Kevin Augus...    soccer\n",
       "2461       G. Bale goal (Real Madrid [1]-0 Leganés) 17'    soccer\n",
       "2462  Daniel Caligiuri (Schalke) penalty miss agains...    soccer\n",
       "2463  Match Thread: Atalanta vs Cagliari [Italian Se...    soccer\n",
       "2464  J.League 2018: Game Week 25 Highlights and Rep...    soccer\n",
       "2465           League Roundup: Ekstraklasa [2018-09-02]    soccer\n",
       "\n",
       "[2466 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soccer_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "## NLP\n",
    "\n",
    "#### Use `CountVectorizer` or `TfidfVectorizer` from scikit-learn to create features from the thread titles and descriptions (NOTE: Not all threads have a description)\n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "#cvec = CountVectorizer(stop_words='english', analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-aad18039b94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scraped_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'total_df' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(total_df).to_csv('scraped_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = total_df['title']\n",
    "y = total_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.loc[total_df['subreddit'] != 'nfl', 'class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english')\n",
    "X_train = cvec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(X_train.todense(),\n",
    "                   columns=cvec.get_feature_names())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score \n",
    "model_lr = LogisticRegression()\n",
    "print(cross_val_score(model_lr, X_train, y_train).mean())\n",
    "model_lr.fit(X_train, y_train)\n",
    "model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "#Previous is the count vectorizer. I am now going to fit a Tfid vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words='english')\n",
    "tvec.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(tvec.transform(corpus).todense(),\n",
    "                   columns=tvec.get_feature_names(),\n",
    "                   index=['nfl', 'soccer'])\n",
    "\n",
    "df.transpose().sort_values('soccer', ascending=False).head(10).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting subreddit using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_def['class'] = nfl_data['title'].map(pd_def['class'] = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - class `0` for one of your subreddits and `1` for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a `RandomForestClassifier` model to predict which subreddit a given post belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. \n",
    "- **Bonus**: Use `GridSearchCV` with `Pipeline` to optimize your `CountVectorizer`/`TfidfVectorizer` and classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process using a different classifier (e.g. `MultinomialNB`, `LogisticRegression`, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "---\n",
    "Put your executive summary in a Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever felt the need to classify different inputs to get important information out of words? My goal was to build a model that is able to accuratly predict whether the title of the reddit post came from one subreddit, or another. \n",
    "\n",
    "Originally, I planned on using the Soccer and NFL subreddits to build a classification model. However, I was not happy with how similar the two were. I scored very highly on the training data, and figured it would be more interesting to use two subreddits of similar topics. I chose to do Personal Finance and Financial Independence. These scores were more interesting to me. \n",
    "\n",
    "Also interesting is the individual coefficients the logistic regression model came up with. It is cool to sort to see the most determinant coefficients for the model. \n",
    "\n",
    "Overall, my process was explore the subreddit, scrape the data, clean and organize the data, and build the various models. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
